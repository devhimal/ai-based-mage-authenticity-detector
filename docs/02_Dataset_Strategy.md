## 2. Dataset Strategy

### 2.1. Dataset Selection Rationale

Given the zero-budget constraint, we will utilize publicly available datasets. A common and effective approach is to combine a dataset of real faces with a dataset of synthetically generated faces.

*   **Real Images:** The **CelebA-HQ** dataset is a high-quality dataset of celebrity faces, which is widely used in academic research and is available under a non-commercial research license. It provides a large and diverse set of real-world images.
*   **Deepfake Images:** We can source deepfake images from datasets like **100K-Generated-Images**, which contains images generated by StyleGAN, or by using a pre-trained GAN available publicly to generate our own dataset of fakes. Another option is the **Deepfake Detection Challenge Dataset (DFDC)**, although it is large and contains videos, we can extract frames to use as images.

For this project, we will create a balanced dataset by taking an equal number of images from CelebA-HQ (Real) and a collection of GAN-generated images (Deepfake).

### 2.2. Validation and Bias Mitigation

*   **Data Splitting:** The dataset will be split into three parts:
    *   **Training Set (70%):** Used to train the CNN model.
    *   **Validation Set (15%):** Used for hyperparameter tuning and to prevent overfitting.
    *   **Test Set (15%):** Used for the final, unbiased evaluation of the model's performance.
*   **Bias Mitigation:** We must acknowledge that publicly available datasets may contain biases (e.g., demographic, age, gender). We will analyze the dataset for any obvious biases and document them. While a zero budget limits our ability to collect more diverse data, we will use data augmentation techniques (see below) to introduce more variance into the training data.

### 2.3. Preprocessing Steps

All images will be standardized to ensure consistency for the model:

1.  **Resizing:** All images will be resized to a uniform dimension, e.g., 256x256 pixels, as expected by the CNN architecture.
2.  **Normalization:** Pixel values will be normalized from the [0, 255] range to [0, 1] or [-1, 1] to aid in faster convergence during training.
3.  **Data Augmentation (Training Set Only):** To increase the robustness of the model and reduce overfitting, we will apply random transformations to the training images, such as:
    *   Horizontal flipping
    *   Slight rotations
    *   Minor brightness and contrast adjustments
